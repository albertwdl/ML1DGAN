{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils import weights_init, compute_acc\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "source": [
    "# 输入参数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(batchSize=100, beta1=0.5, cuda=True, gpu_id=3, lr=0.0002, manualSeed=None, ndf=64, netD='', netG='', ngf=64, ngpu=1, niter=5, num_classes=6, nz=100, outf='.', signalFeatures=4, signalSize=6, slide_stride=1, window=5, workers=0)\nRandom Seed:  7190\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='input batch size')\n",
    "parser.add_argument('--signalFeatures', type=int, default=6, help='the features of signal')\n",
    "parser.add_argument('--signalSize', type=int, default=6, help='the points of signal')\n",
    "parser.add_argument('--nz', type=int, default=110, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "parser.add_argument('--num_classes', type=int, default=10, help='Number of classes for AC-GAN')\n",
    "parser.add_argument('--gpu_id', type=int, default=0, help='The ID of the specified GPU')\n",
    "parser.add_argument('--window', type=int, default=4, help='The size of slide window')\n",
    "parser.add_argument('--slide_stride', type=int, default=1, help='The stride of slide window')\n",
    "\n",
    "opt = parser.parse_args(['--cuda',\n",
    "                         '--batchSize','100',\n",
    "                         '--niter','5',\n",
    "                         '--workers','0',\n",
    "                         '--gpu_id','3',\n",
    "                         '--nz','100',\n",
    "                         '--num_classes','6',\n",
    "                         '--signalSize','6',\n",
    "                         '--signalFeatures','4',\n",
    "                         '--window','5',\n",
    "                         '--slide_stride','1'])\n",
    "print(opt)\n",
    "\n",
    "# specify the gpu id if using only 1 gpu\n",
    "if opt.ngpu == 1:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opt.gpu_id)\n",
    "device = torch.device(\"cuda:\"+str(opt.gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "\n",
    "# some hyper parameters\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "num_classes = int(opt.num_classes)\n",
    "nc = 3"
   ]
  },
  {
   "source": [
    "# 导入数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = torch.from_numpy(scio.loadmat(\"mode_1_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)\n",
    "data_2 = torch.from_numpy(scio.loadmat(\"mode_2_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)\n",
    "data_3 = torch.from_numpy(scio.loadmat(\"mode_3_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)\n",
    "data_4 = torch.from_numpy(scio.loadmat(\"mode_4_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)\n",
    "data_5 = torch.from_numpy(scio.loadmat(\"mode_5_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)\n",
    "data_6 = torch.from_numpy(scio.loadmat(\"mode_6_data.mat\")['X_train']).type(torch.float32).unsqueeze(2).to(device)"
   ]
  },
  {
   "source": [
    "# 滑窗"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window_data(data, window, stride):\n",
    "    # data: torch.ndarray samples*features*1\n",
    "    new_data = data[:-window,:,:]\n",
    "    for i in range(1,window):\n",
    "        new_data = torch.cat((new_data,data[i:-window+i,:,:]),2)\n",
    "    \n",
    "\n",
    "    output = new_data[[x*stride for x in range((new_data.shape[0]-1)//stride+1)], :, :]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_1 = slide_window_data(data_1, opt.window, opt.slide_stride)\n",
    "real_data_2 = slide_window_data(data_2, opt.window, opt.slide_stride)\n",
    "real_data_3 = slide_window_data(data_3, opt.window, opt.slide_stride)\n",
    "real_data_4 = slide_window_data(data_4, opt.window, opt.slide_stride)\n",
    "real_data_5 = slide_window_data(data_5, opt.window, opt.slide_stride)\n",
    "real_data_6 = slide_window_data(data_6, opt.window, opt.slide_stride)"
   ]
  },
  {
   "source": [
    "# 数据加载DataLoader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.cat((real_data_1,real_data_2,real_data_3,real_data_4,real_data_5,real_data_6),0)\n",
    "label_1 = torch.zeros(real_data_1.shape[0])\n",
    "label_2 = torch.ones(real_data_2.shape[0])\n",
    "label_3 = torch.ones(real_data_3.shape[0])*2\n",
    "label_4 = torch.ones(real_data_4.shape[0])*3\n",
    "label_5 = torch.ones(real_data_5.shape[0])*4\n",
    "label_6 = torch.ones(real_data_6.shape[0])*5\n",
    "y_data = torch.cat((label_1,label_2,label_3,label_4,label_5,label_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_dataset = TensorDataset(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=deal_dataset,\n",
    "                        batch_size=opt.batchSize,\n",
    "                        shuffle=True,\n",
    "                        num_workers=opt.workers)"
   ]
  },
  {
   "source": [
    "# 定义生成器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu, nz):\n",
    "        super().__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.nz = nz\n",
    "\n",
    "        self.fc1 = nn.Linear(100,36)\n",
    "        # output batchsize*36*1\n",
    "\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(36,18,2,1,0, bias=False),\n",
    "            nn.BatchNorm1d(18),\n",
    "            nn.ReLU(True)\n",
    "        )# output batchsize*channel(dim)*points batchsize*18*2\n",
    "\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(18,9,2,1,0, bias=False),\n",
    "            nn.BatchNorm1d(9),\n",
    "            nn.ReLU(True)\n",
    "        )# output batchsize*channel(dim)*points batchsize*6*4\n",
    "\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(9,6,2,1,0, bias=False),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU(True)\n",
    "        )# output batchsize*channel(dim)*points batchsize*9*3\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = nn.parallel.data_parallel(self.fc1, input, range(self.ngpu))\n",
    "            fc1 = fc1.view(-1, 36, 1)\n",
    "            tconv2 = nn.parallel.data_parallel(self.tconv2, fc1, range(self.ngpu))\n",
    "            tconv3 = nn.parallel.data_parallel(self.tconv3, tconv2, range(self.ngpu))\n",
    "            tconv4 = nn.parallel.data_parallel(self.tconv4, tconv3, range(self.ngpu))\n",
    "            output = tconv4\n",
    "        else:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = self.fc1(input)\n",
    "            fc1 = fc1.view(-1, 36, 1)\n",
    "            tconv2 = self.tconv2(fc1)\n",
    "            tconv3 = self.tconv3(tconv2)\n",
    "            tconv4 = self.tconv4(tconv3)\n",
    "            output = tconv4\n",
    "        return output"
   ]
  },
  {
   "source": [
    "# 定义鉴别器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu, num__classes=10):\n",
    "        super().__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(6,12,2,1,0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False)\n",
    "        )# output [1, 12, 3]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(12,24,2,1,0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False)\n",
    "        )# output [1, 24, 1]\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(24,48,2,1,0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False)\n",
    "        )# output [1, 48, 1]\n",
    "\n",
    "        self.fc_dis = nn.Linear(48*1, 1)\n",
    "        self.fc_aux = nn.Linear(48*1, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            conv1 = nn.parallel.data_parallel(self.conv1, input, range(self.ngpu))\n",
    "            conv2 = nn.parallel.data_parallel(self.conv2, conv1, range(self.ngpu))\n",
    "            conv3 = nn.parallel.data_parallel(self.conv3, conv2, range(self.ngpu))\n",
    "            flat3 = conv3.view(-1, 48*1)\n",
    "            fc_dis = nn.parallel.data_parallel(self.fc_dis, flat6, range(self.ngpu))\n",
    "            fc_aux = nn.parallel.data_parallel(self.fc_aux, flat6, range(self.ngpu))\n",
    "        else:\n",
    "            conv1 = self.conv1(input)\n",
    "            conv2 = self.conv2(conv1)\n",
    "            conv3 = self.conv3(conv2)\n",
    "            flat3 = conv3.view(-1, 48*1)\n",
    "            fc_dis = self.fc_dis(flat3)\n",
    "            fc_aux = self.fc_aux(flat3)\n",
    "        classes = self.softmax(fc_aux)\n",
    "        realfake = self.sigmoid(fc_dis).view(-1, 1).squeeze(1)\n",
    "        return realfake, classes"
   ]
  },
  {
   "source": [
    "# 初始化生成器和鉴别器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "_netD(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(6, 12, kernel_size=(2,), stride=(1,), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(12, 24, kernel_size=(2,), stride=(1,), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(24, 48, kernel_size=(2,), stride=(1,), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc_dis): Linear(in_features=48, out_features=1, bias=True)\n",
       "  (fc_aux): Linear(in_features=48, out_features=6, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 443
    }
   ],
   "source": [
    "netG = _netG(ngpu, nz).to(device)\n",
    "netG.apply(weights_init)\n",
    "netD = _netD(ngpu, num_classes).to(device)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "source": [
    "# 定义鉴别和辅助分类损失函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_criterion = nn.BCELoss().to(device)\n",
    "aux_criterion = nn.NLLLoss().to(device)"
   ]
  },
  {
   "source": [
    "# 定义优化器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))"
   ]
  },
  {
   "source": [
    "# 训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 初始化变量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor placeholders\n",
    "noise = torch.FloatTensor(opt.batchSize, nz, 1).to(device)\n",
    "dis_label = torch.FloatTensor(opt.batchSize).to(device)\n",
    "aux_label = torch.LongTensor(opt.batchSize).to(device)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_D = 0.0\n",
    "avg_loss_G = 0.0\n",
    "avg_loss_A = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "F:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([200])) is deprecated. Please ensure they have the same size.\n  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (100) != input nelement (200)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-448-fd260965a490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdis_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdis_errD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdis_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0maux_errD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdis_errD_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maux_errD_real\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2474\u001b[0m                       stacklevel=2)\n\u001b[0;32m   2475\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2476\u001b[1;33m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0m\u001b[0;32m   2477\u001b[0m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (100) != input nelement (200)"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        #############################\n",
    "        ## (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        #############################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, label = data\n",
    "        input_samples = real_cpu\n",
    "        batch_size = real_cpu.shape[0]\n",
    "        dis_label.resize_(batch_size).fill_(real_label)\n",
    "        aux_label.resize_(batch_size).copy_(label)\n",
    "        dis_output, aux_output = netD(input_samples)\n",
    "\n",
    "        dis_errD_real = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_real = aux_criterion(aux_output, aux_label)\n",
    "        errD_real = dis_errD_real + aux_errD_real\n",
    "        errD_real.backward()\n",
    "        D_x = dis_output.mean()\n",
    "\n",
    "        # compute the current classification accuracy\n",
    "        accuracy = compute_acc(aux_output, aux_label)\n",
    "\n",
    "        # train with fake\n",
    "        label = torch.randint_like(aux_label, 0, num_classes)\n",
    "        noise = torch.randn(batch_size, nz,1,1).to(device)\n",
    "        class_onehot = torch.zeros((batch_size, num_classes))\n",
    "        class_onehot[np.arange(batch_size), label] = 1\n",
    "        aux_label.copy_(label)\n",
    "\n",
    "        fake = netG(noise)\n",
    "        dis_label.fill_(fake_label)\n",
    "        dis_output, aux_output = netD(fake.detach())\n",
    "        dis_errD_fake = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_fake = aux_criterion(aux_output, aux_label)\n",
    "        errD_fake = dis_errD_fake + aux_errD_fake\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = dis_output.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        #############################\n",
    "        ## (2) Update G network: maximize log(D(G(z)))\n",
    "        #############################\n",
    "        netG.zero_grad()\n",
    "        dis_label.fill_(real_label)\n",
    "        dis_output, aux_output = netD(fake)\n",
    "        dis_errG = dis_criterion(dis_output, dis_label)\n",
    "        aux_errG = aux_criterion(aux_output, aux_label)\n",
    "        errG = dis_errG + aux_errG\n",
    "        errG.backward()\n",
    "        D_G_z2 = dis_output.mean()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # compute the average loss\n",
    "        curr_iter = 1\n",
    "        all_loss_G = avg_loss_G * curr_iter\n",
    "        all_loss_D = avg_loss_D * curr_iter\n",
    "        all_loss_A = avg_loss_A * curr_iter\n",
    "        all_loss_G += errG.item()\n",
    "        all_loss_D += errD.item()\n",
    "        all_loss_A += accuracy\n",
    "        avg_loss_G = all_loss_G / (curr_iter + 1)\n",
    "        avg_loss_D = all_loss_D / (curr_iter + 1)\n",
    "        avg_loss_A = all_loss_A / (curr_iter + 1)\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f (%.4f) Loss_G: %.4f (%.4f) D(x): %.4f D(G(z)): %.4f / %.4f Acc: %.4f (%.4f)'\n",
    "                % (epoch, opt.niter, i, len(dataloader),\n",
    "                errD.item(), avg_loss_D, errG.item(), avg_loss_G, D_x, D_G_z1, D_G_z2, accuracy, avg_loss_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "metadata": {},
     "execution_count": 450
    }
   ],
   "source": [
    "dis_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "metadata": {},
     "execution_count": 455
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}